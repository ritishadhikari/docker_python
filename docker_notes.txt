1. Docker Compose allows management of Multi Container applications in a coordinated way. Spilt
your work into a number of containers. One for the webserver, one for WSGI application server, one
for a Database engine. It introduces compose files where few simple lines of YAML codes, define such
multi-container applications with necessary runtime environment artifacts.

2. Docker Swarm allows to define and run applications stack with multiple services, virtual networks,
volumes, configuration files, secrets etc. Each services is made of one or more containers. Swarm can
scale each services independently, adding more replicas or instances of a particular image or decrease it.
Swarm also enables a controlled upgrade of software running in a service. Rolling Upgrades are possible here.

3. docker build -t pythonincontainers/simple-flask:v1.0 . : Build the Docker Container through Docker File.
Tag it to pythonincontainers/simple-flask:v1.0.

4. docker run --rm -it -p 5001:5000 pythonincontainers/simple-flask:v1.0 : Run that
   --rm : Tells Docker to delete the container when its primary command defined with cmd finishes.
   -it : Tells Docker to launch the container interactively and give access to the current terminal.
   -p 5001:5000 : Binds container's port 5000 to host's 5001.
   pythonincontainers/simple-flask:v1.0 : Image name and tag

5. sudo usermod -aG docker ritish : after typing this, it allows the user to run docker containers
without sudo

6. docker container create --tty --interactive python : Creating a Container ID

7. docker container ps --all : Checking for live  and previous containers.

8. docker container rename keen_volhard ritish_adhikari : Renaming the name of the containers

9. docker container start ritish_adhikari : Starting the container as created before.

10. docker container rm ritish_adhikari: Remove the Container. We can also put the container id
   : "f17109ddebf5", inplace of the name.

11. docker run -it --name ritish_adhikari python : Similar to docker create and docker start command at one go.
-it stands for --interactive and --tty and we create the name ritish_adhikari in the --name itself.

12. The folder which are present inside that of a Docker Container are:
['media', 'usr', 'root', 'bin', 'proc', 'tmp', 'boot', 'opt', 'home', 'dev', 'lib64', 'srv', 'run', 'sys',
'sbin', 'var', 'etc', 'mnt', 'lib', '.dockerenv']
'app' directory does not come by default, but the user needs to explicitly state it.

13. docker cp myfirst.py my:/tmp/myfirst.py : Copying the python script myfirst.py into /tmp/myfirst.py
inside that of a Docker Container. my being the name of the container.

14. exec(open('/tmp/myfirst.py').read()) : Run a python script inside python

15. docker run -it --name my -v ${PWD}:/app python : Sharing the contents of the Present Working directory
with the path as is mentioned and running python code. Rather then copying the contents here, we are
sharing or mounting. But it will open a python interpretor, from where we are supposed to run our
python script.

16. docker run --name my -it -v ${PWD}:/app/ python python /app/myfirst.py : This code is similar to the above,
but rather than opening the python interpretor, post the mounting, it would run the python script -
myfirst.py which resides inside the app folder.

17. docker run --name my -it -v ${PWD}:/app/ python python /bin/bash : Takes through to the linux environment as a
root user, from where we can access any files and even enter inside the app folder and run any python scripts there.

18. docker run -it -v ${PWD}:/app/ -p 5001:5000 python /bin/bash : If we want to run a flask or jango based
applications with port mapping, then we also need to -p host:container. Here port 5001 of the local host
is mapped to port 5000 of the container. We need to run these three for running the flask based .py script:
    - export FLASK_DEBUG=1
    - export FLASK_APP=mythird.py
    - flask run --host=0.0.0.0

19. A container image is a combination of :
    - Filesystem : Directories, Files, Binaries, Data Source code
    - Metadata : Architecture & OS Start-up Command Environment Variables.

20. docker image inspect python : To get the metadata for the image : python.

21. docker image ls : Lists the images availabe in the local repo.

22. docker image prune -a : Major Image Cleanup which does not have any containers running.

23. docker run --rm -d --name simple-flask -p 5001:5000 pythonincontainers/simple-flask:v1.0 : Containers
running properly, without being attached to a terminal.

24. docker logs simple-flask : To get the logs of the container running in a detached state.

25. docker logs --since 3m simple-flask :  To get the logs printed in the last 3 minutes from the container
running in a detached state.

26. docker logs --since 3m --tail 3 simple-flask : To get the logs of the last 3 operations since the
last 3 minutes.

27. docker logs -f simple-flask : To follow up with the container with -it kind.

28. docker attach simple-flask: To attch the container which got broken down by pressing control c.

29. docker run -it --rm --name myp -m 200m --memory-swap 300m --cpus 0.6 python:3.7 : Running a Docker Container with
restrictions on Memory(ram) and cpu. If the memory gets filled up, then it will free upto  another 100 MB from
RAM to Disk.

30. docker stats : To show the statistics of all the running containers.

31. docker ps -aq : Gives the list of all stopped containers.

32. docker rm -f $(docker ps -aq) : To remove all the stopped container. Once removed, they cannot be started again.

33. docker network create my-net : Creating a Network in docker which will help to connect a flask based
application inside a Centos container.

34. docker run -d --name simple-flask --network my-net ritish/flask : Running a Flask Container with the network
created above.

35. docker run --rm -it --name centos --network my-net centos : Running a centos container with the same network.

36. curl simple-flask:5000/TEST : Running the Flask app from inside Centos with the network id. This network is
aiding in running multiple containers.

37. docker run -d --name proxy-server --network my-net nginx : Also creating an nginx server connecting with then
same network name to be run inside centos along with simple-flask.

38. curl proxy-server:80 : Running the proxy server inside of centos.

39. docker run --rm -it --link simple-flask:webserver centos : This allows to link simple-flask container
inside of centos.

40. curl webserver:5000 : After linking we run this command to run the flask application inside of centos.

41. env | grep WEBSERVER : gives the lists of webserver details connected to the container in centos.

42. docker volume create my-vol : Creating a Docker Volume, so that even after removing a container, once starting
the same container, the items inside of the container exists.

43. docker run -it --name my --volume my-vol:/app python bash : Running a Docker Container with the volume
being attached to the app folder inside the container.

44. cat <<-EOF >script.py :
> print("Hello from a Container")
> EOF
Creating a script.py inside the container. Even after doing - docker rm my, if we use
docker run -it --name my --volume my-vol:/app python bash again, the script.py will reside.

45. docker volume ls : Lists the docker volumes in the systems.

46. docker volume inspect my-vol : Gives more detail on our created docker : my-vol.

47. docker volume rm my-vol : Removing the my-vol volume from docker. Before this, remove the container
by doing : docker rm my or docker rm -f my.

Each container we create in Docker, gets its own network stack. Default IP address of connection is 172.17.0.0/16.
It connects to home network in NAT mode.

48. docker network ls : Gives the names of the container available by default. Ex: bridge, host, my-net (created)
and none.

When we create a new container and don't attach it to a specific network explicitly, then it is
connected to bridge by default.

49. docker run --rm -it --network host alpine : Container in alpine connected to host network. Here network
specific applications can only be run. Such container has no network isolation and all its published ports
are directly visible in host's system. In short we don't have to map port.

50. docker network rm new-net : Remove a network. We have to make sure, there are no active Containers connected
with that network.

51. docker ps --filter network=my-net : Lists the containers attached to a specific network. Here - mynet.

52. docker network connect my-addr alpine2 : Connecting a container called alpine2 with a network my-addr.
alpine 2 was not initially connected to my-addr but the default bridge network. Post the connection, the
container alpine 2 can ping another container alpine1 connected with my-addr originally through ping -c 1 alpine1.

53. docker network disconnect my-addr alpine2 : Disconneting a Container alpine2 from a network my-addr.

Internal Networks are used to limit the internet connectivity running an image we don't trust.

54. docker network create --internal int-net : Creating an internal container int-net

55. docker run -dit --name int1 --network int-net alpine : Attaching a detached container int1 to int-net
container.

56. docker run --rm -it --name int2 --network int-net alpine : Creating another container int2.
If we ping ping -c 1 int1 then we will get the ping, but if we ping www.google.com, theen we won't get
the ping as it is connected to an internal network.

57. docker run -d -P --name flask-hello flask-hello:1.0 : Run a docker image flask-hello:1.0 with -P which signifies
take which ever port the container port 5000 points to host. Get the host port by doing docker ps and check from
the container flask-hello. We can also do docker image inspect flask-hello:1.0 or docker inspect flask-hello to
get meta data information. The later also shows the host port details : docker inspect flask-hello | grep Host.

58. docker login : To login to docker hub through username and password.

59. docker logout : Logout from docker hub.

60. docker tag ritishadhikari/flask-hello:2.0 ritishadhikari/flask-hello:latest : Tagging an image as the latest

61. docker push ritishadhikari/flask-hello : Post the tagging, pushing it to the docker hub.

62. docker run -it --rm --name ritish4rmweb -p 5001:5000 ritishadhikari/flask-hello:latest : After we have pushed the
image, even if we have deleted the image in our local, we can still run the image by calling this command.

63. docker run -d -p 8000:8000 -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock
-v portainer_data:/data portainer/portainer : We can set up a GUI portainer through this way. portainer
allows to add/remove and do other stuffs related to Images, Containers, Networks, Volumes and others interactively.

Docker Machine is a tool used to create and manage the Docker Runtime environments encapsulated in Virtual Machines.
Such VMs can be created and run either on a local host - our development system or on a remote system and also in the
cloud.

64. docker-machine create test-vm --virtualbox-no-vtx-check : Creating a Docker Machine. The --virtualbox-no-vtx-check
command is not mandatory but if not provided, the docker-machine won't get created.

65. docker-machine env test-vm : Sets the path variable for TLS,Host,Certificate Path and Machine Name.

66. docker-machine stop test-vm : Stops the Docker Machines.

67. docker-machine start test-vm : Starts the Docker Machine which was stopped.

66. docker-machine rm -f test-vm : Remove Docker Machine.

67. unset DOCKER_HOST DOCKER_MACHINE_NAME DOCKER_TLS_VERIFY DOCKER_CERT_PATH : After removing the Docker Machine,
remove the Docker path variable associated with the Docker Machine.

68. docker-machine ip test-vm : Gives the machine ip address.

69. docker-machine create --driver google --google-project healthy-system-283205 --google-zone us-west4-c gce-machine        :
Create a docker-machine with google. healthy-system-283205 is the project id.

70. gcloud compute firewall-rules create machine-8000 --action allow --target-tags "docker-machine" --source-ranges
"0.0.0.0/0" --rules "tcp:8000" : Define the port options

71. docker commit manual manual-image:1.0 : Tagging a container to an image.
When we do docker create and docker run,the container gets created without the image.
Hence to create or tag an image out of the containers we run this command.
The following supportive commands were run while running the above command.
docker create -it --name manual -p 5000:5000 python:3.7 /bin/bash
docker cp hello.py manual:/app
docker cp start-app.sh manual:/app
docker start -i manual
>chmod +x /app/start-app.py

72. docker commit --change "CMD /app/start-app.sh" manual manual-image:1.1 : Tagging a container to an image.
But this time, we are explicitly mentioning the workflow that the /app-start-app.sh needs to be started
after the bash shell gets created.

73. docker build -f Dockerfile.env -t automated-image:1.1 . : To build an image when the name of the Dockerfile
is other than the standard name : Dockerfile. Here the name of the dockerfile is Dockerfile.env.

74. FROM alpine
    FROM ubuntu:18.04
    FROM python
    : Creating three images, alpine versions of Ubuntu and python.

The .dockerignore file will contain the list of files and directories which need not be copied
from the source to docker daemon. Anything to be exempted from ignoring post labelling through a
wildcard expression, needs to be stated with an exclaimation (!); its's like negating the negation.

The basic differences between ADD and COPY is that, while ADD can actually add tar files and files
from HTML to the docker daemon, the COPY command can't do this above two activities.

75. docker build -t flask-hello https://github.com/pythonincontainers/flask-hello.git : Building an image
directly from the github. The Dockerfile must be present inside the repository to enable the build.

RUN command inside a JSON file runs in an non interactive way. We must make sure that commands we run with
the RUN command do not expect any user input.

Python official Image contains software package installation subsystem with "apt-get", as it is based
on Debian flavour of Linux.

When we use a volume in our docker file and then copy relevant files into it, the volume command stores the
information into it. This volume (either manually created or auto created during runtime) can be mounted
to any other images during Docker RUntime.

Any Docker File command placed before the Volume Command, can update files under future mount point,
but command after mount point cannot. Check for Docker.vol1 file under accessory_docker_files. Lecture -48.

76. docker inspect -f "ENTRYPOINT={{ .Config.Entrypoint }} CMD={{ .Config.Cmd }}" child : Here we are inspecting
the Entrypoint and Cmd of the Child Image.

77. docker build -t parent -f Dockerfile.parent .
    docker build -t child -f Dockerfile.child .  : parent-child image relationships. All the commands
    from the parent are inherited to the child, until there is a same command in the child which is also
    there in the parent. At that time, the child's command is executed and not the parent. Lecture 49.

78. In case of multiple entrypoints and cmd declarations in one docker file, the very last prevails.

79. docker run --rm child one two three: substituting the CMD command in Docker File with one two three.

80. docker run --rm --entrypoint python3 child args.py helloworld : Altering the entrypoint command during
Docker runtime. here child is the name of the image, python3 is the name of the entrypoint while args.py helloworld
is the name of cmd which is assumed.

CMD in shell format without list form does not work well with non empty entry point (automatic entrypoint),
as it is converted through shell format internally before execution of the file.

When ever we use Entrypoint in shell form, the CMD is ignored. Shell form is suitable only when either of
entrypoint or cmd is used.

ENV defines environment variables in a Dockerfile. When a container is created, or run, a value of such variables
can be changed by using "-env" option. Environment variables can be used to define a server address or may be a
database name or any other configuration parameter. This helps to build a powerful universal image and then
configure it at runtime.

Variables defined with arg instructions exists only during the build time.

81. docker build -t args -f Dockerfile.arg  --build-arg Flask_Ver=1.0.0 --build-arg Python_Image_Tag=3.7-alpine . :
Building an image with a defined version of flask and Python_Image_Tag through --build-arg command. --build-arg
option overrides all occurences of ARG variable declarations. Lecture 50. ./Dockerfile-arg/Dockerfile.env.

The Commands with which Arg Variables can be used are : FROM, RUN, ENV,COPY,ADD,EXPOSE,LABEL,STOPSIGNAL,
USER,VOLUME,WORKDIR.

If we generate a lot of images and keep them, searching for the right one may be easier by labelling images.

Typical Python Application configuration options include use of Environment Variables, Configuration files and
command line options and arguments.

In ./reusable/Dockerfile.env we run the python script - config-reader.py along with by passing the environment
variables - CONFIG_COLOR and CONFIG_SHAPE from the Docker File.

82. docker run -it --rm -e CONFIG_SHAPE=dot env : We can label our config variable during docker runtime by
using this command. This will overwrite the CONFIG_SHAPE pre initialized in Dockerfile.env.

In ./reusable/Dockerfile.file, we pass a config file called default.ini through which the config values
are picked up in the python script - config-reader.py

83. docker run -it --rm -v ${PWD}/app/configs/blue_circle.ini:/app/default.ini file : To run a separate file
other than the default.ini at run time, even after building the Dockerfile.file with default.ini initially.

In ./reusable/Dockerfile.args, we are passing the arguments for color and shape to the the python script -
config-reader.py

84. docker run -it --rm args --color "silver" --shape "pentagon" : Changing the cmd from the terminal for the
Docker build with Dockerfile.args.

After running a container without --rm tag, we can stop it by pressing ctrl+c and if we start the same container
again by docker start -ai container name (defined through --name during docker run), we can get back to the old
working state of the container.

We can pass an environment variable to a docker file or during docker runtime ny using -e which will
then be passed on to the cmd file. This can enable the automated capability testing for required libraries.
Example : ./buildtime-runtime/Dockerfile.runtime & ./buildtime-runtime/requirements.txt

Container runtime provides automatic restart capability, which can be very helpful to enable high availability
of service.

Multistage Build helps us to copy relevant modules created in a directory from one image to another. The first
image can be a bigger image while the second image can be a smaller image. The final image size belongs to that
of the smaller image.
./multistage/Dockerfile.cython-multi. Lecture 54.

85. docker run -it --rm -v ${PWD}:/app -w /app cython-full : The addition of -w is it signifies the current
working directory if not explicitly stated in the Dockerfile. Ex. ./buildcustom/Dockerfile.cython0.28.5-full.

In ./buildcustom/Dockerfile.cython-flask-slim we achieve three things:
a. smaller Image size as we are doing multi stage build
b. faster build : since we don't have to run pip install requirements.txt
c. faster execution : since we are using cython based modules.


86. docker export -o rootfs.tar python-3.7 : This export the containers file python-3.7 which was
created by using docker run -it --name python-3.7 python:3.7-slim bash and removing the unwanted modules.
This rootfs.tar will be used for security testing.

87. docker cp multistage_container:/app/factors_flask.py . : Copying  factors_flask.py from
inside a container to outside in the host's present file path.

89.
docker run -d --name db --network polls_net -e POSTGRES_PASSWORD=myprecious postgres : Run a postgres
container
docker run -it --rm --network polls_net postgres psql -h db -U postgres : Create Superuser by
connecting to the host db
CREATE USER pollsuser WITH PASSWORD 'pollspass' CREATEDB; : Creating a User
CREATE DATABASE pollsdb WITH OWNER pollsuser; : Creating a Database
\du : Lists the name of users and Superusers
\l : Lists the databases created.

90. docker run -d --name db --network polls_net -e POSTGRES_DB=pollsdb
-e POSTGRES_USER=pollsuser -e POSTGRES_PASSWORD=pollspass
-v polls_vol:/var/lib/postgresql/data postgres : Creating the DB, the user,
Password all at one go without the need to create a superuser. Here pollsuser has superuser
privileges assigned. Also creating a Volume so that even when this db container is removed,
the data residing inside the /var/lib/postgresql/data location stays on.
This way of launching Postgres is easiest and least cumbersome.
